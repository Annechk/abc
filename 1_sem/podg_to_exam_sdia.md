# Ответы на экзаменационные вопросы по курсу "Структуры данных и алгоритмы"

---

## 1. Определение структур данных в программировании

**Структуры данных** — это способ организации и хранения данных в компьютере для эффективного доступа и модификации. Они определяют, как данные физически расположены в памяти и как с ними можно работать.

**Общие характеристики:**
- **Организация данных:** способ расположения элементов в памяти
- **Операции доступа:** время для получения элемента
- **Операции модификации:** время для добавления, удаления, изменения элементов
- **Использование памяти:** объем памяти, необходимый для хранения

**Классификация:**
1. **Линейные:** массивы, стеки, очереди, списки
2. **Нелинейные:** деревья, графы, хеш-таблицы

**Важность:** правильный выбор структуры данных определяет эффективность алгоритма и производительность программы.

---

## 2. Простейшие (базовые) структуры данных

**Массивы** — последовательный набор элементов одного типа, хранящихся в смежных ячейках памяти.
- **Доступ:** O(1) по индексу
- **Вставка/удаление:** O(n) в худшем случае

**Статические массивы:** размер фиксирован при создании, выделяется память на стеке или глобально.

**Динамические массивы:** размер может изменяться во время выполнения программы, используется динамическое выделение памяти (new, malloc).

**Стеки (Stack)** — LIFO (Last In, First Out) структура с операциями push (добавление) и pop (удаление).

**Очереди (Queue)** — FIFO (First In, First Out) структура с операциями enqueue (добавление в конец) и dequeue (удаление из начала).

**Деки (Deque)** — двусторонняя очередь, позволяет добавление и удаление с обоих концов.

**Простые списки (Linked Lists)** — динамическая структура, состоящая из узлов, связанных указателями.

**Мультисписки** — списки с несколькими типами ссылок между узлами для представления сложных связей.

---

## 3. Понятие стека

**Определение:** стек — это LIFO структура данных, где последний добавленный элемент первым удаляется.

**Принцип работы:**
1. **Оператор push** `stack.append(element)` добавляет элемент в верхнюю часть стека
2. **Оператор pop** `stack.pop()` удаляет и возвращает верхний элемент
3. **Оператор peek** `stack[-1]` возвращает верхний элемент без удаления
4. **Оператор isEmpty** `len(stack) == 0` проверяет, пуст ли стек

**Основные операции:** push O(1), pop O(1), peek O(1), isEmpty O(1)

**Виды реализации:**
- Массив с индексом top
- Связный список с указателем на вершину

**Примеры организации (Python):**
```python
stack = []
stack.append(1)  # push
element = stack.pop()  # pop
```

**Применение:** отмена операций (undo), обход лабиринта, проверка скобок, вычисление выражений.

---

## 4. Понятие очереди в программировании

**Определение:** очередь — это FIFO структура данных, где первый добавленный элемент первым удаляется.

**Принцип работы:**
1. **Оператор enqueue** `queue.append(element)` добавляет элемент в конец очереди
2. **Оператор dequeue** `queue.popleft()` удаляет элемент из начала очереди
3. **Оператор front** `queue[0]` возвращает первый элемент
4. **Оператор isEmpty** `len(queue) == 0` проверяет пустоту очереди

**Основные операции:** enqueue O(1), dequeue O(1), front O(1)

**Виды реализации:**
- На основе массива с двумя указателями (front, rear)
- На основе связного списка

**Применение:**
- Очереди обслуживания в системах
- Поиск в ширину (BFS)
- Печать документов
- Обработка задач в порядке поступления

**Примеры реализации на Python:**
```python
from collections import deque
q = deque()
q.append(element)  # enqueue
q.popleft()  # dequeue
```

---

## 5. Дек как структура данных

**Определение:** дек (deque, двусторонняя очередь) — это структура данных, позволяющая добавление и удаление элементов с обоих концов.

**Принцип работы:**
1. **Оператор pushFront** `deq.appendleft(element)` добавляет в начало
2. **Оператор pushBack** `deq.append(element)` добавляет в конец
3. **Оператор popFront** `deq.popleft()` удаляет из начала
4. **Оператор popBack** `deq.pop()` удаляет из конца

**Основные операции:** O(1) для всех операций с обоих концов

**Реализация:**
- На основе двусвязного списка
- На основе циклического массива

**Частные случаи:**
- Если использовать только pushBack и popFront — это очередь (FIFO)
- Если использовать только pushBack и popBack — это стек (LIFO)

**Примеры на Python:**
```python
from collections import deque
d = deque()
d.appendleft(1)  # pushFront
d.append(2)      # pushBack
d.popleft()      # popFront
```

---

## 6. Приоритетная очередь

**Определение:** приоритетная очередь — это структура данных, где элементы упорядочены по приоритету, и элемент с наивысшим приоритетом удаляется первым.

**Особенности:** каждый элемент имеет связанный приоритет; элемент с выше приоритетом служится раньше, независимо от порядка добавления.

**Принцип работы:**
1. **Оператор insert** `pq.put((priority, element))` добавляет элемент с приоритетом
2. **Оператор extractMax** `pq.get()` удаляет элемент с максимальным приоритетом
3. **Оператор peekMax** `pq.queue[0]` возвращает элемент с максимальным приоритетом
4. **Оператор isEmpty** `pq.empty()` проверяет пустоту

**Основные операции:** insert O(log n), extractMax O(log n), peekMax O(1)

**Реализация:**
- На основе бинарной кучи (O(log n) для вставки и удаления)
- На основе массива (O(n) для поиска максимума)

**Примеры применения:** планирование задач, алгоритм Дейкстры, кодирование Хаффмана, симуляция событий.

---

## 7. Понятие списка и мультисписка

**Список (Linked List)** — динамическая структура данных, состоящая из узлов, каждый из которых содержит данные и ссылку на следующий узел.

**Принцип работы:**
1. **Оператор создания узла** `Node(data, next)` создает узел с данными и указателем next
2. **Оператор добавления в начало** `new_node.next = head; head = new_node` вставляет в начало за O(1)
3. **Оператор добавления в конец** `current.next = new_node` добавляет в конец за O(n)
4. **Оператор удаления** `current.next = current.next.next` удаляет узел за O(1) если известна позиция

**Основные операции:** поиск O(n), вставка O(1) если позиция известна, удаление O(1)

**Реализация способы:** односвязные списки, двусвязные списки, циклические списки

**Мультисписки** — списки с несколькими типами ссылок (например, несколько next указателей), используются для представления сложных структур данных и графов.

**Применение:** стеки, очереди, графы, кэши, списки с прямым доступом, реализация хеш-таблиц.

---

## 8. Бинарная куча

**Определение:** бинарная куча — это полное бинарное дерево, где каждый родитель больше (max-heap) или меньше (min-heap) своих детей.

**Типы:**
- **Max-heap:** родитель больше своих детей, максимальный элемент в корне
- **Min-heap:** родитель меньше своих детей, минимальный элемент в корне

**Устройство:**
1. **Оператор индексирования** `left_child = 2*i+1, right_child = 2*i+2` определяет позицию детей
2. **Оператор heapify** `if arr[child] > arr[parent]: swap(arr[child], arr[parent])` восстанавливает свойство кучи
3. **Оператор insert** `arr.append(element); heapify()` добавляет элемент за O(log n)
4. **Оператор extractMax** `swap(arr[0], arr[-1]); arr.pop(); heapify()` удаляет максимум за O(log n)

**Основные операции:** insert O(log n), extractMax O(log n), buildHeap O(n)

**Применение:** приоритетные очереди, сортировка кучей, поиск k максимальных элементов.

---

## 9. Биноминальная куча

**Определение:** биноминальная куча — это лес биноминальных деревьев, где каждое дерево удовлетворяет свойству кучи.

**Свойства:**
- Биноминальное дерево степени k имеет 2^k узлов
- Высота биноминального дерева степени k равна k
- Куча содержит не более одного дерева каждой степени

**Принцип работы:**
1. **Оператор merge** объединяет две кучи путем слияния деревьев одинаковой степени за O(log n)
2. **Оператор insert** добавляет новое дерево степени 0 и выполняет merge за O(log n)
3. **Оператор extractMin** удаляет корень минимального дерева и выполняет merge за O(log n)
4. **Оператор decreaseKey** уменьшает значение ключа и поднимает узел за O(log n)

**Основные операции:** insert O(log n), extractMin O(log n), merge O(log n), decreaseKey O(log n)

**Представление:** каждое дерево хранится как указатель на корень с ссылками на детей и сибилингов.

**Примеры реализации:** используется в алгоритме Дейкстры и других алгоритмах на графах.

---

## 10. Куча Фибоначчи

**Определение:** куча Фибоначчи — это расслабленная структура данных на основе кучи, позволяющая выполнять операции decreaseKey в амортизированном времени O(1).

**Особенности:** деревья в куче Фибоначчи имеют более сложную структуру и разрыхлены (relax) для улучшения производительности операций.

**Операции над кучей Фибоначчи:**
1. **Оператор insert** `add_tree_to_root_list()` добавляет новую кучу в корневой список за амортизированное O(1)
2. **Оператор extractMin** удаляет минимальный элемент и консолидирует деревья за амортизированное O(log n)
3. **Оператор decreaseKey** уменьшает ключ и отмечает узел для дальнейшей консолидации за амортизированное O(1)
4. **Оператор delete** удаляет элемент за амортизированное O(log n)

**Амортизированные временные сложности:**
- insert: O(1)
- extractMin: O(log n)
- decreaseKey: O(1)
- delete: O(log n)

**Недостатки:** сложная реализация, большие константные множители, неэффективно на практике для малых данных.

**Амортизированный анализ:** метод оценки средней сложности операции за длинную последовательность операций.

---

## 11. Понятие и виды базовых операций в программировании

**Базовые операции** — это простые операции, выполняемые за O(1) времени (чтение, запись, сравнение, арифметические операции).

**Виды базовых операций:**
- **Арифметические:** +, -, *, /, %
- **Операции присваивания:** =
- **Логические операции:** &&, ||, !
- **Операции сравнения:** ==, !=, <, >, <=, >=
- **Операции доступа:** индексирование массива arr[i], доступ к элементу структуры

**Трудоемкость операций:**
- **Чтение/запись в память:** O(1)
- **Поиск в неотсортированном массиве:** O(n)
- **Поиск в отсортированном массиве (двоичный поиск):** O(log n)

**Амортизационный анализ:** метод оценки средней стоимости операции за длинную последовательность операций, даже если отдельные операции дорогие.

**Пример:** динамический массив при увеличении размера имеет стоимость O(1) в амортизированном смысле, несмотря на дорогое перемещение элементов.

---

## 12. Хеш-таблицы как структуры данных

**Определение:** хеш-таблица — это структура данных, которая реализует ассоциативный массив (словарь), используя хеш-функцию для отображения ключей на значения.

**Компоненты хеш-таблицы:**
1. **Оператор хешения** `hash_value = hash_function(key)` преобразует ключ в индекс массива
2. **Оператор доступа** `table[hash_value] = value` сохраняет значение по вычисленному индексу
3. **Оператор поиска** `value = table[hash_function(key)]` находит значение за O(1) в среднем

**Принцип работы:**
- Ключ преобразуется хеш-функцией в индекс
- По этому индексу хранится значение в массиве
- Коллизии (когда разные ключи дают одинаковый хеш) разрешаются методом цепочек или открытой адресацией

**Виды:** открытая адресация, метод цепочек (chaining), двойное хеширование

**Операции:** insert O(1) в среднем, delete O(1) в среднем, lookup O(1) в среднем

**Применение:** кэши, индексирование баз данных, системы управления памятью, счетчики частот.

---

## 13. Хеш-функции в хеш-таблицах

**Определение:** хеш-функция — это функция, которая отображает ключ произвольного размера в целое число в диапазоне [0, m-1], где m — размер хеш-таблицы.

**Принцип работы:**
1. **Оператор модульного деления** `hash(key) = key % m` вычисляет индекс, где m — размер таблицы
2. **Оператор умножения** `hash(key) = floor(m * (key * 0.618 % 1))` использует золотое сечение для распределения
3. **Оператор сложения цифр** суммирует символы или цифры для строковых ключей
4. **Оператор преобразования строки** преобразует строку в число через полиномиальное хеширование

**Виды хеш-функций:**
- Деление по модулю
- Умножение на константу
- Универсальное хеширование
- Крипто-хеширование (SHA, MD5)

**Эффективность хеш-функций:**
- Должна быть быстро вычисляемой (O(1) для простых хешей)
- Должна равномерно распределять ключи по таблице
- Должна минимизировать количество коллизий

**Применение:** определение целостности данных, криптография, поиск дубликатов.

---

## 14. Алгоритмы электронной цифровой подписи (ЭЦП)

**Суть технологии:** ЭЦП — это математический метод для подтверждения подлинности и целостности электронных документов.

**Виды ЭЦП:**
- **RSA:** основана на сложности факторизации больших чисел
- **DSA (Digital Signature Algorithm):** использует дискретный логарифм
- **ECDSA:** использует эллиптические кривые

**Принцип работы:**
1. **Оператор хеширования** `hash = hash_function(document)` вычисляет хеш документа
2. **Оператор подписания** `signature = encrypt(hash, private_key)` шифрует хеш приватным ключом
3. **Оператор верификации** `hash2 = decrypt(signature, public_key); hash == hash2` проверяет подпись дешифрованием открытым ключом
4. **Сравнение хешей** подтверждает подлинность и целостность документа

**Особенности реализации:**
- Используется асимметричное шифрование (приватный и открытый ключи)
- Невозможно поддельать подпись без приватного ключа
- Проверка может быть выполнена кем угодно с открытым ключом

**Примеры:** подпись контрактов, аутентификация транзакций в блокчейне, подтверждение авторства.

---

## 15. Понятие дерева Меркла и технология блокчейн

**Дерево Меркла** — это бинарное дерево хешей, где каждый лист содержит хеш данных, а каждый внутренний узел содержит хеш конкатенации хешей своих детей.

**Структура дерева Меркла:**
1. **Оператор хеширования листов** `leaf_hash = hash(data_block)` вычисляет хеш каждого блока данных
2. **Оператор объединения хешей** `parent_hash = hash(left_hash + right_hash)` создает хеш родителя
3. **Оператор корневого хеша** `merkle_root = hash_tree(all_hashes)` вычисляет корневой хеш всего дерева
4. **Оператор верификации** позволяет проверить целостность данных, используя только корневой хеш

**Блокчейн — технология распределенного реестра:**
- **История:** впервые использована в 2008 году в Bitcoin
- **Актуальность:** применяется в криптовалютах, смарт-контрактах, системах учета
- **Текущая ситуация:** развивающаяся технология, используется в множестве приложений

**Примеры использования:**
- Криптовалюты (Bitcoin, Ethereum)
- Системы учета с неизменяемым логом
- Смарт-контракты
- Верификация цепочки поставок

---

## 16. Прямая адресация в хеш-таблицах

**Преимущества:** доступ за O(1) за счет прямого отображения ключей на индексы, простая реализация, отсутствие коллизий.

**Принцип работы:**
1. **Оператор индексирования** `index = key` используется напрямую как индекс таблицы
2. **Оператор вставки** `table[key] = value` сохраняет значение по ключу
3. **Оператор поиска** `value = table[key]` находит значение за O(1)
4. **Оператор удаления** `table[key] = null` удаляет значение за O(1)

**Реализация:**
- Требует массив размером от 0 до максимального ключа
- Все ячейки инициализируются как пустые (null)
- Доступ к любому ключу за O(1)

**Недостатки:**
- Требует огромное количество памяти, если ключи разреженные или большие
- Неэффективна для больших диапазонов ключей
- Работает только для целых положительных ключей или ключей с ограниченным диапазоном

**Применение:** примитивные счетчики, битовые флаги для малых диапазонов значений.

---

## 17. Методы разрешения коллизий в хеш-таблицах

**Коллизия** — ситуация, когда хеш-функция дает одинаковый результат для разных ключей.

**Методы разрешения коллизий:**

### Метод цепочек (Chaining):
1. **Оператор создания цепочки** `table[index] = linked_list()` создает связный список для каждого индекса
2. **Оператор вставки** `table[hash_key].append(key_value_pair)` добавляет пару в цепочку за O(1)
3. **Оператор поиска** проходит по цепочке за O(1 + load_factor)
4. **Оператор удаления** удаляет из цепочки за O(1 + load_factor)

### Открытая адресация (Linear Probing):
1. **Оператор пробирования** `index = (hash(key) + i) % m` ищет следующую свободную ячейку
2. **Оператор вставки** добавляет элемент в первую найденную пустую ячейку за O(1)
3. **Оператор поиска** проходит по последовательности пробирования за O(1 + load_factor)

### Двойное хеширование:
1. **Оператор вторичного хеша** `index = (hash1(key) + i * hash2(key)) % m` использует две хеш-функции
2. **Преимущество:** уменьшает кластеризацию, присущую линейному пробированию

**Универсальное семейство хеш-функций:**
- **Свойства:** для любых двух ключей вероятность коллизии ≤ 1/m
- **Применение:** гарантирует хорошее распределение ключей в среднем случае
- **Принцип работы:** случайный выбор хеш-функции из семейства перед инициализацией таблицы

---

## 18. Понятие нелинейных структур данных

**Определение:** нелинейные структуры данных не имеют линейного порядка элементов и поддерживают сложные отношения между элементами.

**Виды:**
- **Деревья:** иерархическая структура с родителями и детями
- **Графы:** общая структура с произвольными связями между узлами
- **Таблицы хеш:** неупорядоченные отображения ключей на значения

**Особенности реализации:**
- Используются указатели для связи элементов
- Требуют более сложных алгоритмов для навигации и модификации
- Позволяют представлять сложные отношения и иерархии

**Применение:** файловые системы, графы социальных сетей, системы рекомендаций, сетевые протоколы.

---

## 19. Деревья как структуры данных

**Определение:** дерево — это нелинейная структура данных, состоящая из узлов (вершин) и ребер, образующих иерархию с одним корневым узлом и без циклов.

**Особенности:**
- Каждый узел (кроме корня) имеет одного родителя
- Каждый узел может иметь несколько детей
- Путь от корня до каждого узла уникален
- Дерево с n узлами имеет n-1 ребер

**Представление:**
1. **Оператор связи узлов** `node.children = [child1, child2, ...]` связывает родителя и детей
2. **Оператор обхода в глубину** `visit(node); for child in node.children: DFS(child)` обходит дерево рекурсивно
3. **Оператор обхода в ширину** `queue.add(root); while queue: node = queue.pop(); queue.add(node.children)` обходит по уровням

**Базовые алгоритмы:**
- Поиск элемента: O(n) в худшем случае, O(log n) в сбалансированном дереве
- Вставка элемента: зависит от типа дерева
- Удаление элемента: зависит от типа дерева
- Определение высоты: O(n) рекурсивный обход

---

## 20. Бинарные и AVL-деревья

**Бинарное дерево поиска (BST)** — дерево, где каждый узел имеет не более двух детей, и для каждого узла все значения в левом поддереве меньше, а в правом — больше.

**Определение BST:**
1. **Оператор сравнения** `if value < node.value: left else: right` определяет направление поиска
2. **Оператор поиска** рекурсивно спускается в дерево за O(log n) в среднем
3. **Оператор вставки** добавляет новый узел с сохранением свойства BST за O(log n) в среднем
4. **Оператор удаления** удаляет узел и перестраивает дерево за O(log n) в среднем

**AVL-дерево** — самобалансирующееся бинарное дерево, где разница высот левого и правого поддеревьев не превышает 1.

**Операции AVL-дерева:**
- **Оператор проверки баланса** `balance = height(left) - height(right)` определяет дисбаланс
- **Оператор правого поворота** `rotate_right()` балансирует дерево при дисбалансе -1 (перекос влево)
- **Оператор левого поворота** `rotate_left()` балансирует дерево при дисбалансе 1 (перекос вправо)
- **Оператор двойного поворота** комбинирует повороты для сложных случаев

**Особенности реализации:** гарантирует O(log n) для всех операций (поиск, вставка, удаление).

**Применение:** базы данных, файловые системы, системы с требованиями к предсказуемой производительности.

---

## 21. Красно-черные, префиксные и В-деревья

**Красно-черные деревья** — самобалансирующиеся бинарные деревья с дополнительным цветовым свойством.

**Определение:** каждый узел окрашен в красный или черный цвет с правилами:
- Корень и листья черные
- Детей красного узла не могут быть красными
- Все пути от узла до листьев содержат одинаковое количество черных узлов

**Операции:** поиск O(log n), вставка O(log n), удаление O(log n)

**Префиксные деревья (Trie)** — деревья для хранения строк, где каждый узел представляет символ.

**Применение Trie:** автозаполнение, проверка орфографии, маршрутизация IP-адресов, поиск подстрок.

**В-деревья (B-trees)** — многоветвистые деревья, оптимизированные для систем с блочным доступом к памяти.

**Свойства В-дерева степени t:**
- Каждый узел содержит от t-1 до 2t-1 ключей
- Каждый внутренний узел имеет от t до 2t детей
- Все листья находятся на одинаковой высоте

**Поддерживаемые операции:** поиск O(log n), вставка O(log n), удаление O(log n)

**Применение:** файловые системы (NTFS, ext4), базы данных (индексирование).

---

## 22. Предмет теории алгоритмов

**Определение:** теория алгоритмов — раздел информатики, изучающий методы решения задач через описание процессов обработки данных.

**Ключевые направления:**
- **Анализ сложности:** изучение временной и пространственной сложности алгоритмов
- **Разработка алгоритмов:** создание эффективных методов решения задач
- **Классификация задач:** определение сложности решения (P, NP, NP-полные)
- **Оптимизация:** поиск наиболее эффективных алгоритмов

**Основные задачи теории алгоритмов:**
1. Доказательство корректности алгоритма
2. Анализ эффективности (время и память)
3. Сравнение различных алгоритмов для одной задачи
4. Определение нижних границ сложности

**История развития:** начинается с работ Тьюринга, Гёделя, Черча в 1930-х годах.

**Применение:** оптимизация программного обеспечения, криптография, искусственный интеллект, обработка больших данных.

**Место в науке:** фундаментальная дисциплина, объединяющая математику и информатику.

---

## 23. Формальное описание задачи в теории алгоритмов

**Формальное описание задачи:**
1. **Определение входных данных** — множество всех допустимых входов
2. **Определение выходных данных** — множество всех допустимых выходов
3. **Определение отношения** — связь между входом и выходом

**Пример:** сортировка массива
- Вход: массив целых чисел
- Выход: отсортированный массив
- Отношение: элементы выхода — это переставленные элементы входа в неубывающем порядке

**Блок-схемы в теории алгоритмов:**
1. **Оператор начало/конец** — овальные символы, обозначают начало и конец алгоритма
2. **Оператор обработки** — прямоугольники, обозначают операции присваивания или вычисления
3. **Оператор условия** — ромб, обозначает ветвление в зависимости от условия
4. **Оператор цикла** — специальные символы, обозначают повторение блока кода

**Ограничения блок-схем:**
- Не масштабируются для сложных алгоритмов
- Сложны для чтения и модификации больших программ
- Не стандартизированы в полной мере

---

## 24. UML (Unified Modeling Language) для моделирования программного обеспечения

**Основные характеристики:** стандартизированный язык для визуализации, спецификации и документирования систем.

**Цели применения:**
- Визуализация архитектуры системы
- Коммуникация между разработчиками
- Документирование требований и дизайна

**Преимущества UML:**
- Стандартный язык, понятный всем разработчикам
- Поддержка различных видов диаграмм
- Интеграция с инструментами разработки
- Помощь в планировании и анализе

**Виды диаграмм:**
- **Диаграмма классов:** показывает структуру классов и отношения
- **Диаграмма последовательности:** показывает взаимодействие объектов во времени
- **Диаграмма деятельности:** показывает процесс выполнения алгоритма
- **Диаграмма компонентов:** показывает архитектуру системы
- **Диаграмма развертывания:** показывает физическое распределение компонентов

**Практика применения:** используется в корпоративной разработке, разработке игр, системном дизайне.

---

## 25. Размерность задачи в теории алгоритмов

**Определение:** размерность (или размер) задачи — количество входных данных, обозначаемое обычно как n.

**Теоретическое значение:** позволяет анализировать, как алгоритм масштабируется с увеличением входных данных.

**Практические примеры:**
- Сортировка массива из n элементов
- Поиск в графе с n вершинами и m ребрами
- Умножение матриц размером n×n
- Поиск подстроки в тексте длиной n

**Влияние размерности на сложность:**
- O(n) алгоритм медленнее на 10 раз при размерности в 10 раз больше
- O(n²) алгоритм медленнее на 100 раз при размерности в 10 раз больше
- O(2^n) алгоритм становится неиспользуемым уже при n > 30

---

## 26. Понятие трудоемкости (сложности) алгоритма

**Определение:** трудоемкость алгоритма — количество элементарных операций, необходимых для выполнения алгоритма в зависимости от размера входных данных.

**Виды сложности:**
- **Временная сложность:** количество операций как функция размера входа
- **Пространственная сложность:** объем памяти, требуемый для выполнения алгоритма

**Методы оценки:**
1. **Подсчет операций** подсчитывает количество базовых операций в худшем, среднем и лучшем случаях
2. **Анализ асимптотической сложности** определяет класс функции роста (O-нотация)
3. **Практическое тестирование** измеряет реальное время выполнения на различных входах

**Базовые нотации:**
- **Big-O (О):** верхняя граница сложности
- **Big-Omega (Ω):** нижняя граница сложности
- **Big-Theta (Θ):** точная оценка сложности

---

## 27. Нотация BigO

**Определение:** Big-O нотация описывает верхнюю границу роста функции трудоемкости при стремлении размера входа к бесконечности.

**Представление:** f(n) = O(g(n)) означает, что существуют константы c и n₀ такие, что f(n) ≤ c·g(n) для всех n ≥ n₀.

**Примеры нотаций Big-O:**
- **O(1):** константное время (доступ к элементу массива)
- **O(log n):** логарифмическое время (двоичный поиск)
- **O(n):** линейное время (линейный поиск)
- **O(n log n):** линейно-логарифмическое время (сортировка слиянием)
- **O(n²):** квадратичное время (сортировка пузырьком)
- **O(2^n):** экспоненциальное время (переборные алгоритмы)
- **O(n!):** факториальное время (генерация перестановок)

**Другие виды нотаций:**
- **Big-Omega (Ω):** нижняя граница — алгоритм выполняется не менее Ω(g(n)) операций
- **Big-Theta (Θ):** точная граница — алгоритм выполняется ровно Θ(g(n)) операций в асимптотическом смысле
- **Little-O (o):** строгая верхняя граница — f(n) растет медленнее, чем g(n)
- **Little-Omega (ω):** строгая нижняя граница — f(n) растет быстрее, чем g(n)

---

## 28. Виды трудоемкости алгоритма

**Описание в Big-O:**
- **Лучший случай:** наиболее благоприятный сценарий входных данных
- **Средний случай:** ожидаемая сложность для случайных входов
- **Худший случай:** наихудший сценарий входных данных

**Примеры:**
- **Линейный поиск:** лучший O(1), средний O(n), худший O(n)
- **Быстрая сортировка:** лучший O(n log n), средний O(n log n), худший O(n²)
- **Двоичный поиск:** O(log n) во всех случаях

**Типичная структура анализа трудоемкости:**
1. Определить размер входа (n)
2. Подсчитать количество операций в зависимости от n
3. Определить доминирующий член функции
4. Выразить сложность в О-нотации

**Важность оценки алгоритмической сложности:**
- Позволяет предсказать масштабируемость
- Помогает выбрать оптимальный алгоритм для задачи
- Критична для систем реального времени
- Определяет практическую применимость алгоритма

---

## 29. Асимптотики Ο, Ω, Θ

**Большое О (O - Big-O):**
- **Определение:** f(n) = O(g(n)) если существуют c > 0 и n₀ ≥ 0 такие, что f(n) ≤ c·g(n) для всех n ≥ n₀
- **Представление:** верхняя граница роста функции
- **Пример:** f(n) = 3n² + 2n + 1 = O(n²)

**Большое Омега (Ω - Big-Omega):**
- **Определение:** f(n) = Ω(g(n)) если существуют c > 0 и n₀ ≥ 0 такие, что f(n) ≥ c·g(n) для всех n ≥ n₀
- **Представление:** нижняя граница роста функции
- **Пример:** f(n) = 3n² + 2n + 1 = Ω(n²)

**Большое Тета (Θ - Big-Theta):**
- **Определение:** f(n) = Θ(g(n)) если f(n) = O(g(n)) и f(n) = Ω(g(n)) одновременно
- **Представление:** точная асимптотическая граница
- **Пример:** f(n) = 3n² + 2n + 1 = Θ(n²)

**Примеры нотаций:**
- O(1) — константное время
- Ω(n) — минимум линейное время
- Θ(n log n) — точно линейно-логарифмическое время

---

## 30. Понятие числовых алгоритмов

**Основные типы:**
- **Арифметические алгоритмы:** вычисление факториала, НОД, возведение в степень
- **Алгоритмы поиска корней:** метод Ньютона, метод половинного деления
- **Численное интегрирование:** формула трапеций, правило Симпсона
- **Решение систем линейных уравнений:** метод Гаусса, метод LU-разложения

**Общая структура числового алгоритма:**
1. **Инициализация:** подготовка переменных и установка начальных значений
2. **Итеративное вычисление:** повторение вычислений до достижения точности
3. **Проверка сходимости:** проверка условия остановки (точность, количество итераций)
4. **Возврат результата:** возвращение полученного приближения

**Примеры:**
- Вычисление факториала: O(n) операций
- НОД чисел a и b: O(log min(a, b)) операций алгоритмом Евклида
- Возведение в степень: O(log n) операций методом быстрого возведения в степень

**Практика использования:** научные вычисления, инженерное моделирование, финансовые расчеты.

---

## 31. Получисленные алгоритмы

**Определение:** получисленные алгоритмы — алгоритмы, в которых числовая часть (обработка чисел) комбинируется с нечисловой частью (логика, управление потоком).

**Ключевые преимущества:**
- Эффективно решают задачи, требующие как логики, так и вычисления
- Часто встречаются в реальных приложениях
- Позволяют оптимизировать специфические расчеты

**Примеры:**
- **Проверка простоты числа:** логика цикла + деление (модуль)
- **Криптография:** манипуляция битами + операции над большими числами
- **Обработка изображений:** логика пикселей + математические преобразования
- **Финансовые расчеты:** условная логика + вычисления процентов

**Практика использования:** криптография, обработка сигналов, системы реального времени.

---

## 32. Комбинаторные алгоритмы

**Определение:** комбинаторные алгоритмы — алгоритмы для решения задач, связанных с перечислением, подсчетом или оптимизацией комбинаторных объектов.

**Основные типы:**
- **Генерация перестановок:** все возможные упорядочения элементов
- **Генерация сочетаний:** все возможные подмножества элементов
- **Поиск кратчайшего пути:** задачи на графах
- **Раскраска графа:** назначение цветов вершинам графа
- **Задача о ранце:** выбор оптимального подмножества предметов

**Примеры реализаций:**
- Генерация перестановок: O(n·n!) операций
- Генерация сочетаний: O(C(n,k)) операций
- Поиск кратчайшего пути: O(n² + m) для алгоритма Дейкстры

**Применение:** оптимизация, планирование, криптография.

---

## 33. Рекурсия

**Определение:** рекурсия — техника, при которой функция вызывает саму себя с упрощенным вариантом задачи.

**Случаи рекурсии:**
- **Базовый случай (Base case):** условие, при котором рекурсия прекращается
- **Рекурсивный случай:** вызов функции с упрощенным параметром

**Рекурсивные алгоритмы:**
1. **Оператор базового случая** `if n <= 1: return 1` определяет условие завершения
2. **Оператор рекурсивного вызова** `return n * factorial(n-1)` упрощает задачу
3. **Стек вызовов** автоматически управляет локальными переменными каждого уровня

**Примеры реализаций:**
- **Факториал:** `factorial(n) = n * factorial(n-1), factorial(0) = 1` — O(n) время, O(n) память
- **Числа Фибоначчи:** `fib(n) = fib(n-1) + fib(n-2), fib(0)=0, fib(1)=1` — O(2^n) наивный подход
- **Быстрое возведение в степень:** логарифмическая рекурсия — O(log n)
- **Бинарный поиск:** рекурсивное деление массива пополам — O(log n)

---

## 34. Полиномиальные и псевдополиномиальные алгоритмы

**Полиномиальные алгоритмы** — алгоритмы, время выполнения которых ограничено полиномом от размера входа.

**Основные типы:**
- **O(n):** линейные алгоритмы (линейный поиск)
- **O(n²):** квадратичные алгоритмы (сортировка пузырьком)
- **O(n³):** кубические алгоритмы (умножение матриц наивным методом)
- **O(n log n):** линейно-логарифмические алгоритмы (сортировка слиянием)

**Примеры реализации:** поиск, сортировка, базовые операции на графах.

**Псевдополиномиальные алгоритмы** — алгоритмы, время выполнения которых зависит не только от размера входа, но и от значений чисел в входе.

**Основные типы:**
- **Динамическое программирование для задачи о ранце:** O(n·W), где W — максимальный вес
- **Алгоритм Беллмана-Форда для поиска кратчайших путей:** O(n·m)

**Примеры реализации:** задача о ранце, поиск подстроки, расчет НОД.

---

## 35. Экспоненциальные алгоритмы

**Определение:** экспоненциальные алгоритмы — алгоритмы, время выполнения которых растет экспоненциально с размером входа.

**Основные типы:**
- **O(2^n):** переборные алгоритмы на битовых строках (генерация всех подмножеств)
- **O(n!):** алгоритмы на перестановках (задача коммивояжера, генерация перестановок)
- **O(3^n):** алгоритмы раскраски или разбиения (3-раскраска графа)

**Примеры реализаций:**
- **Генерация всех подмножеств:** `2^n` подмножеств, O(2^n) операций
- **Решение задачи коммивояжера:** O(n·2^n) методом динамического программирования
- **Проверка всех возможных расписаний:** O(n!) операций

**Применение:** малые входные данные (n ≤ 20), NP-полные задачи, криптоанализ.

---

## 36. Понятие рекуррентного уравнения (рекуррентного соотношения)

**Определение:** рекуррентное уравнение — математическое выражение, определяющее последовательность через предыдущие члены.

**Виды рекуррентных уравнений:**
- **Линейные однородные:** T(n) = a·T(n-1) (факториал, степень)
- **Линейные неоднородные:** T(n) = a·T(n-1) + f(n) (числа Фибоначчи, сортировка)
- **Разделяй и властвуй:** T(n) = a·T(n/b) + f(n) (сортировка слиянием, быстрая сортировка)

**Методы решения:**
- **Метод подстановки:** угадать решение и проверить индукцией
- **Метод итераций:** раскрыть рекурсию несколько уровней и найти закономерность
- **Основная теорема (Master Theorem):** для рекуррентных уравнений вида T(n) = a·T(n/b) + f(n)

**Полное рекуррентное уравнение:** включает начальные условия и полное определение всех частей.

**Примеры и ошибки:**
- **Неправильно:** забыть базовый случай, привести к бесконечной рекурсии
- **Ошибка округления:** неправильно обработать нецелое деление в рекурсии
- **Ошибка сложения:** неправильно сложить члены при раскрытии рекурсии

---

## 37. Алгоритмы сортировки

**Определение:** сортировка — процесс упорядочивания элементов последовательности в определенном порядке.

**Основные типы алгоритмов сортировки:**
- **Сравнивающие:** основаны на сравнении элементов (сортировка пузырьком, вставками, слиянием)
- **Распределяющие:** основаны на распределении элементов по категориям (счетная сортировка, поразрядная)

**Алгоритм сортировки слиянием (Merge Sort):**

**Пошаговая структура:**
1. **Оператор разделения** `mid = len(arr) // 2; left = arr[:mid]; right = arr[mid:]` разбивает массив пополам
2. **Оператор рекурсивной сортировки** `mergeSort(left); mergeSort(right)` сортирует половины
3. **Оператор слияния** `merge(left, right)` объединяет отсортированные половины
4. **Сравнение элементов** `if left[i] <= right[j]: result.append(left[i])` выбирает меньший элемент

**Особенности реализации:**
- Требует дополнительной памяти O(n) для слияния
- Стабильная сортировка (сохраняет порядок равных элементов)
- Временная сложность O(n log n) во всех случаях

---

## 38. Алгоритмы сортировки на принципе «разделяй и властвуй»

**Сущность принципа:**
1. **Разделение:** разбить задачу на подзадачи меньшего размера
2. **Решение:** решить подзадачи рекурсивно (или прямо, если малые)
3. **Объединение:** объединить решения подзадач в решение исходной задачи

**Примеры алгоритмов:**
- **Сортировка слиянием:** T(n) = 2·T(n/2) + O(n) = O(n log n)
- **Быстрая сортировка:** T(n) = T(k) + T(n-k-1) + O(n), средне O(n log n)
- **Поиск медианы:** T(n) = T(n/5) + T(7n/10) + O(n)

**Особенности реализации:**
- Требуют рекурсивного мышления
- Часто очень эффективны благодаря экспоненциальному уменьшению размера
- Основная теорема помогает анализировать сложность

---

## 39. Алгоритм быстрой сортировки

**Определение:** быстрая сортировка (Quick Sort) — алгоритм на основе принципа разделяй и властвуй, выбирающий опорный элемент и разделяющий массив на две части.

**Пошаговая структура:**
1. **Оператор выбора опоры** `pivot = arr[random_index]` выбирает опорный элемент
2. **Оператор разделения** `partition(arr, pivot)` разбивает массив на меньшие и большие элементы
3. **Оператор рекурсивной сортировки** `quickSort(left); quickSort(right)` сортирует части
4. **Сравнение и переброска** элементы перемещаются относительно опоры за O(n)

**Достоинства:**
- Очень быстрый на практике (часто быстрее сортировки слиянием)
- Использует O(log n) дополнительной памяти
- Хорошо работает с кэшем процессора

**Недостатки:**
- Худший случай O(n²) при плохом выборе опоры
- Нестабильная сортировка
- Требует реализации функции разделения

**Временная сложность:** лучший/средний O(n log n), худший O(n²)

**Примеры реализации:** во всех современных языках программирования как встроенная функция.

---

## 40. Алгоритм сортировки вставкой

**Определение:** сортировка вставками (Insertion Sort) — алгоритм, который разделяет массив на отсортированную и неотсортированную части, вставляя элементы из неотсортированной части в правильную позицию отсортированной.

**Принцип и пошаговая структура:**
1. **Оператор выбора элемента** `key = arr[i]` берет элемент из неотсортированной части
2. **Оператор сравнения** `while j >= 0 and arr[j] > key:` находит правильную позицию
3. **Оператор сдвига** `arr[j+1] = arr[j]; j -= 1` сдвигает большие элементы вправо
4. **Оператор вставки** `arr[j+1] = key` вставляет элемент в правильную позицию

**Достоинства:**
- Простая реализация
- Эффективна для малых массивов (n < 50)
- Стабильная сортировка
- Эффективна для почти отсортированных массивов (O(n))

**Недостатки:**
- Квадратичная сложность в среднем и худшем случаях
- Медленнее чем сортировка слиянием для больших массивов

**Временная сложность:** лучший O(n), средний/худший O(n²)

---

## 41. Алгоритм сортировки выбором

**Описание:** сортировка выбором (Selection Sort) — алгоритм, который разделяет массив на две части, находит минимальный элемент в неотсортированной части и меняет его с первым элементом неотсортированной части.

**Пошаговая структура:**
1. **Оператор поиска минимума** `min_idx = i; for j in range(i+1, n):` находит индекс минимального элемента
2. **Оператор сравнения** `if arr[j] < arr[min_idx]: min_idx = j` обновляет индекс минимума
3. **Оператор обмена** `arr[i], arr[min_idx] = arr[min_idx], arr[i]` меняет местами элементы
4. **Оператор перемещения границы** граница отсортированной части сдвигается на 1

**Достоинства:**
- Простая реализация и понимание
- Предсказуемая производительность (всегда O(n²))
- Минимальное количество свопов (не более n)

**Недостатки:**
- Всегда O(n²) даже на отсортированных данных
- Нестабильная сортировка
- Не адаптивна к входным данным

**Временная сложность:** O(n²) во всех случаях

---

## 42. Алгоритм сортировки «пузырьком»

**Определение:** сортировка пузырьком (Bubble Sort) — алгоритм, который многократно проходит по массиву, сравнивая и меняя местами соседние элементы, если они находятся в неправильном порядке.

**Пошаговая структура:**
1. **Оператор внешнего цикла** `for i in range(n):` проходит по массиву несколько раз
2. **Оператор внутреннего цикла** `for j in range(n-i-1):` сравнивает соседние элементы
3. **Оператор сравнения и обмена** `if arr[j] > arr[j+1]: swap(arr[j], arr[j+1])` меняет неправильно упорядоченные пары
4. **Оптимизация** `if not swapped: break` останавливает алгоритм если уже отсортирован

**Достоинства:**
- Простая реализация
- Стабильная сортировка
- Адаптивна к отсортированным данным (с оптимизацией)

**Недостатки:**
- Медленная сортировка O(n²) даже в среднем случае
- Плохая локальность памяти
- Редко используется в производстве

**Временная сложность:** лучший O(n) (если отсортирован и есть оптимизация), средний/худший O(n²)

---

## 43. Алгоритм сортировки Шелла

**Определение:** сортировка Шелла (Shell Sort) — алгоритм, который обобщает сортировку вставками, сортируя элементы, расположенные на определенном расстоянии друг от друга, постепенно уменьшая это расстояние.

**Пошаговая структура:**
1. **Оператор инициализации промежутка** `gap = len(arr) // 2` выбирает начальный промежуток
2. **Оператор сортировки с промежутком** сортирует элементы через промежуток используя вставки
3. **Оператор уменьшения промежутка** `gap = gap // 2` уменьшает промежуток
4. **Оператор завершения** `while gap > 0:` повторяет до промежутка 1

**Достоинства:**
- Лучше чем простые сортировки на практике
- Эффективна для среднего размера массивов
- Использует O(1) дополнительной памяти

**Недостатки:**
- Сложная для анализа временная сложность
- Не стабильная сортировка
- Производительность зависит от выбора последовательности промежутков

**Временная сложность:** зависит от последовательности промежутков, обычно O(n^(3/2)) или лучше

---

## 44. Алгоритм пирамидальной сортировки

**Определение:** пирамидальная сортировка (Heap Sort) — алгоритм, использующий структуру данных бинарная куча для эффективной сортировки массива.

**Пошаговая структура:**
1. **Оператор построения кучи** `buildHeap(arr)` преобразует массив в max-heap за O(n)
2. **Оператор извлечения максимума** `swap(arr[0], arr[i])` перемещает максимум в конец за O(log n)
3. **Оператор восстановления кучи** `heapify(arr, 0)` восстанавливает свойство max-heap
4. **Оператор цикла** повторяет шаги 2-3 для всех элементов

**Достоинства:**
- Гарантированная O(n log n) временная сложность
- Использует O(1) дополнительной памяти (на месте)
- Предсказуемая производительность

**Недостатки:**
- На практике медленнее чем быстрая сортировка (худшие константные коэффициенты)
- Нестабильная сортировка
- Плохая локальность памяти

**Временная сложность:** O(n log n) во всех случаях

---

## 45. Алгоритмы поиска

**Определение:** поиск — процесс нахождения элемента с заданным значением в последовательности или структуре данных.

**Основные типы:**
- **Последовательный поиск (Linear Search):** проходит по всем элементам O(n)
- **Двоичный поиск (Binary Search):** делит пополам на каждом шаге O(log n)
- **Интерполирующий поиск (Interpolation Search):** оценивает позицию элемента O(log log n)

**Алгоритм последовательного поиска:**
1. **Оператор инициализации** `for i in range(len(arr)):` проходит по элементам
2. **Оператор сравнения** `if arr[i] == target: return i` проверяет каждый элемент
3. **Оператор возврата** `return -1` возвращает индекс или индикатор "не найдено"

**Алгоритм двоичного поиска:**
1. **Оператор инициализации границ** `left = 0; right = len(arr) - 1` устанавливает границы
2. **Оператор деления пополам** `mid = (left + right) // 2` выбирает средний элемент
3. **Оператор сравнения** `if arr[mid] == target: return mid` проверяет середину
4. **Оператор сужения границ** `left = mid + 1` или `right = mid - 1` сужает диапазон поиска

**Алгоритм интерполирующего поиска:**
1. **Оператор оценки позиции** `pos = left + (target - arr[left]) / (arr[right] - arr[left]) * (right - left)` оценивает позицию
2. **Оператор перепроверки** проверяет оценку и сужает границы похоже на двоичный поиск

**Особенности реализации:** двоичный поиск требует отсортированный массив, интерполирующий — равномерно распределенные данные.

---

## 46. Алгоритмы Фибоначчи и двоичного дерева (BST) поиска

**Алгоритм поиска Фибоначчи (Fibonacci Search):**

**Основные шаги:**
1. **Оператор инициализации Фибоначчи** `fib_m = fibonacci(m)` выбирает число Фибоначчи ≥ размера массива
2. **Оператор исключения диапазона** `offset = mid - fib_m_1` вычисляет смещение для следующей проверки
3. **Оператор сравнения** `if arr[mid] == target: return mid` проверяет элемент
4. **Оператор сужения** использует меньшие числа Фибоначчи для сужения диапазона

**Сложность:** O(log n), аналогично двоичному поиску

**Интерфейс:** `fib_search(arr, target) -> index`

**Поиск в двоичном дереве поиска (BST):**

**Основные шаги:**
1. **Оператор рекурсивного спуска** `if target < node.val: search(node.left)` спускается в левое поддерево
2. **Оператор сравнения** `if target == node.val: return node` находит элемент
3. **Оператор спуска вправо** `else: search(node.right)` спускается в правое поддерево
4. **Оператор базового случая** `if node is None: return None` возвращает None если не найдено

**Сложность:** O(log n) в среднем случае для сбалансированного дерева, O(n) в худшем случае

**Примеры реализаций:** двоичный поиск в массиве, поиск в BST, AVL-дерево с поиском.

---

## 47. Динамическое программирование

**Определение:** динамическое программирование (DP) — техника решения задач путем разбиения на перекрывающиеся подзадачи и сохранения результатов для переиспользования.

**Подходы:**
- **Top-down (мемоизация):** рекурсивный подход с кэшированием результатов
- **Bottom-up (табуляция):** итеративный подход, заполняющий таблицу снизу вверх

**Преимущества:**
- Эффективно для задач с оптимальной подструктурой
- Может существенно ускорить решение
- Часто преобразует экспоненциальное время в полиномиальное

**Недостатки:**
- Требует больше памяти для хранения результатов
- Сложнее в реализации и понимании
- Не все задачи подходят для DP

**Популярные задачи:**
- **Задача о ранце:** выбор предметов с максимальной стоимостью и ограничением по весу
- **Числа Фибоначчи:** вычисление с мемоизацией O(n) вместо O(2^n)
- **Наибольшая общая подстрока:** поиск самой длинной общей подпоследовательности
- **Редакционное расстояние:** минимальное количество операций для преобразования строки

---

## 48. Понятие «жадных» алгоритмов

**Определение:** жадный алгоритм — алгоритм, который на каждом шаге выбирает локально оптимальный вариант в надежде найти глобальный оптимум.

**Виды:**
- **Алгоритмы выбора:** выбор задач с максимальной награде (Activity Selection)
- **Алгоритмы разбиения:** разбиение ресурсов (Fractional Knapsack)
- **Алгоритмы минимального остовного дерева:** Крускал, Прим

**Принципы:**
1. **Критерий выбора:** определить, как выбирать на каждом шаге
2. **Проверка оптимальности:** убедиться, что локальный выбор ведет к глобальному оптимуму
3. **Доказательство корректности:** доказать математически, что алгоритм оптимален

**Условия применимости:**
- Задача должна иметь оптимальную подструктуру
- Жадный выбор должен привести к оптимуму
- Задача должна проявлять свойство жадного выбора

**Преимущества:**
- Простая реализация
- Быстрое выполнение O(n log n) или лучше
- Интуитивно понятны

**Недостатки:**
- Не работают для всех задач оптимизации
- Могут дать субоптимальные решения для некоторых задач
- Требуется доказательство корректности

---

## 49. Алгоритмы поиска подстроки в строке

**Определение задачи:** найти позицию(и) подстроки pattern в строке text.

**Классы алгоритмов:**
- **Наивный алгоритм:** попытка каждой позиции O(nm)
- **KMP (Knuth-Morris-Pratt):** использование таблицы отказов O(n+m)
- **Boyer-Moore:** сканирование справа налево O(n/m) в среднем
- **Rabin-Karp:** хеширование подстрок O(n+m) в среднем

**Наивный алгоритм:**
1. **Оператор внешнего цикла** `for i in range(len(text)-len(pattern)):` проходит по позициям
2. **Оператор сравнения подстроки** `if text[i:i+len(pattern)] == pattern:` проверяет совпадение
3. **Оператор возврата** `return i` возвращает позицию при совпадении
4. **Оператор возврата при неудаче** `return -1` если подстрока не найдена

**KMP алгоритм:**
1. **Оператор построения таблицы** вычисляет таблицу отказов для pattern за O(m)
2. **Оператор поиска** использует таблицу для перепрыгивания через несовпадения за O(n)

**Сравнительный анализ:**
- **Наивный:** просто, но медленно O(nm)
- **KMP:** быстро O(n+m), но сложнее
- **Boyer-Moore:** очень быстро на практике O(n/m)
- **Rabin-Karp:** хорошо для множественного поиска или поиска в 2D

---

## 50. Алгоритмы поиска в реальном времени

**Определение и основные понятия:**
- **Real-time search:** поиск с гарантированным временем ответа
- **Bounded response time:** время ответа ≤ определенное значение
- **Anytime algorithms:** алгоритмы, дающие все лучшее решение с течением времени

**Базовые характеристики:**
- Гарантированное время завершения
- Приемлемое качество решения
- Использование ограниченных ресурсов (процессор, память)

**Виды алгоритмов:**
- **A* поиск:** информированный поиск с эвристикой O(b^d), где b — коэффициент ветвления
- **D* Lite:** динамический поиск для изменяющихся окружений
- **Iterative Deepening:** поиск в глубину с ограничением по времени

**Пошаговая структура поиска с ограничением по времени:**
1. **Оператор инициализации таймера** `start_time = time.now()` фиксирует время начала
2. **Оператор проверки времени** `if time.elapsed() > max_time: stop_search()` останавливает при превышении
3. **Оператор поиска** выполняет поиск в цикле
4. **Оператор возврата лучшего результата** возвращает найденный результат при остановке

**Применимость:** робототехника, автомобили, игры, системы мониторинга реального времени.

**Примеры реализаций:** шахматные движки (с ограничением по времени), навигационные системы.

**Преимущества:** гарантированное время ответа, предсказуемая производительность.

**Ограничения:** качество решения может быть ниже оптимального при малом времени.

---

## 51. Алгоритмы полного перебора

**Понятие:** алгоритмы полного перебора (brute-force) — проверка всех возможных решений без оптимизации.

**Особенности:**
- Гарантированно находит оптимальное решение
- Очень медленные для больших входов
- Используются для понимания задачи или верификации

**Применимость:**
- Малые входные данные (n < 20)
- Отсутствие лучшего алгоритма
- Проверка корректности других алгоритмов

**Пошаговая структура:**
1. **Оператор генерации** `generate_all_solutions()` создает все возможные решения
2. **Оператор проверки** `check_validity(solution)` проверяет условия
3. **Оператор оценки** `evaluate(solution)` вычисляет значение качества
4. **Оператор выбора лучшего** `best_solution = max(solutions)` выбирает оптимальное

**Примеры реализации:**
- **Задача коммивояжера:** перебор всех перестановок городов O(n!)
- **Проверка всех подмножеств:** перебор всех 2^n подмножеств
- **Перебор всех перестановок:** генерация n! перестановок

**Преимущества:** гарантированно правильное решение, просто понять и реализовать.

**Недостатки:** экспоненциальная или факториальная сложность, неприменимо для больших входов.

---

## 52. Приближённые и эвристические алгоритмы

**Понятие приближённых алгоритмов:** алгоритмы, находящие решение, близкое к оптимальному, за полиномиальное время.

**Виды:**
- **Гарантированные приближения:** находят решение ≤ c × оптимум (c — коэффициент)
- **Эвристические:** основаны на опыте и часто хорошо работают
- **Метаэвристические:** общие методы (simulated annealing, genetic algorithms)

**Особенности применения:**
- Для NP-полных задач, где оптимум недоступен за полиномиальное время
- Когда небольшое отклонение от оптимума приемлемо
- Когда нужен быстрый результат

**Пошаговая структура:**
1. **Инициализация** `solution = greedy_solution()` начинает с простого решения
2. **Улучшение** `solution = improve(solution)` пытается улучшить решение
3. **Локальный поиск** `while improvement: solution = best_neighbor(solution)` ищет лучшие соседей
4. **Возврат** `return solution` возвращает найденное решение

**Примеры реализаций:**
- **Приближение задачи о ранце:** жадный алгоритм дает 1-1/b приближение
- **Приближение задачи коммивояжера:** алгоритм минимального остовного дерева дает 2-приближение
- **Локальный поиск:** начинает с любого решения и улучшает через соседей

**Преимущества:** полиномиальное время, часто хорошо работают на практике.

**Недостатки:** не гарантирует оптимум, качество зависит от конкретного случая.

---

## 53. Графы как структура данных

**Определение:** граф — структура данных, состоящая из вершин (узлов) и ребер (дуг), соединяющих эти вершины.

**Виды:** ориентированные, неориентированные, взвешенные, ненаправленные.

**Базовые алгоритмы на графах:**

### DFS (Depth-First Search):
1. **Оператор посещения** `visit(vertex)` отмечает вершину как посещенную
2. **Оператор рекурсии** `for neighbor in vertex.neighbors: DFS(neighbor)` рекурсивно посещает соседей
3. **Оператор отхода** возвращается в предыдущую вершину
4. **Сложность:** O(V + E)

### BFS (Breadth-First Search):
1. **Оператор инициализации очереди** `queue.add(start)` добавляет начальную вершину
2. **Оператор обхода** `while queue: vertex = queue.pop()` обходит по уровням
3. **Оператор добавления соседей** добавляет непосещенных соседей в очередь
4. **Сложность:** O(V + E)

### Алгоритм Дейкстры (поиск кратчайшего пути):
1. **Оператор инициализации расстояний** `dist[start] = 0; dist[other] = infinity`
2. **Оператор выбора вершины** выбирает непосещенную вершину с минимальным расстоянием
3. **Оператор релаксации** `dist[neighbor] = min(dist[neighbor], dist[current] + weight)`
4. **Сложность:** O((V + E) log V)

### Алгоритм Беллмана-Форда (поиск кратчайшего пути с отрицательными весами):
1. **Инициализация расстояний** аналогично Дейкстре
2. **Релаксация ребер** повторяется V-1 раз для всех ребер
3. **Проверка отрицательных циклов** перепроверяет ребра в V-й раз
4. **Сложность:** O(V·E)

### Алгоритм Флойда-Уоршелла (все пары кратчайших путей):
1. **Инициализация матрицы расстояний** из матрицы весов
2. **Тройной цикл** `for k: for i: for j: dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])`
3. **Сложность:** O(V³)

### Алгоритм Крускала (минимальное остовное дерево):
1. **Сортировка ребер** по весу
2. **Union-Find структура** для проверки циклов
3. **Добавление ребер** если они не создают цикл
4. **Сложность:** O(E log E)

### Алгоритм Прима (минимальное остовное дерево):
1. **Выбор начальной вершины** и добавление в MST
2. **Выбор минимального ребра** из текущей MST к новой вершине
3. **Добавление вершины** в MST и повторение
4. **Сложность:** O((V + E) log V)

### Алгоритм Форда-Фалкерсона (максимальный поток):
1. **BFS поиск увеличивающего пути** от источника к стоку
2. **Вычисление потока** по найденному пути
3. **Обновление графа остатков** с остаточными емкостями
4. **Сложность:** O(V·E²)

### Алгоритм Диница (максимальный поток):
1. **Построение слоистого графа** посредством BFS
2. **Поиск блокирующего потока** через слоистый граф
3. **Повторение** до отсутствия пути
4. **Сложность:** O(V²·E)

**Примеры реализаций:** навигационные системы, социальные сети, компьютерные сети.

**Преимущества и недостатки:**
- DFS: просто, хорошо для поиска в глубину, может использовать много памяти
- BFS: находит кратчайший путь в неориентированных графах, требует очередь
- Дейкстра: оптимален для положительных весов, неэффективен для отрицательных
- Беллман-Форд: работает с отрицательными весами, медленнее Дейкстры
- Флойд-Уоршелл: все пары путей, медленный для больших графов
- Крускал/Прим: находят MST эффективно

---

## 54. Алгоритмы ML и нейронных сетей

### Алгоритм KNN (K-Nearest Neighbors):

**Определение:** алгоритм машинного обучения, классифицирующий объект на основе k ближайших соседей в обучающем наборе.

**Пошаговая структура:**
1. **Оператор вычисления расстояния** `distance = euclidean(test_point, train_point)` вычисляет расстояние до каждого обучающего примера
2. **Оператор сортировки** сортирует примеры по расстоянию
3. **Оператор выбора k соседей** берет k ближайших примеров
4. **Оператор голосования** `class = most_common(neighbors)` выбирает класс по большинству
5. **Сложность:** O(k·n) для классификации одной точки

**Применимость:** классификация, рекомендации, простые задачи.

**Преимущества:** просто реализовать, часто работает хорошо.

**Недостатки:** медленный предсказание, чувствителен к масштабированию, требует всех обучающих данных.

### Алгоритм K-means:

**Определение:** алгоритм кластеризации, разбивающий данные на k кластеров путем минимизации внутридисперсии кластеров.

**Пошаговая структура:**
1. **Инициализация центроидов** `centroids = random_points(k)` выбирает k случайных центра
2. **Назначение точек** `point.cluster = nearest_centroid(point)` присваивает каждую точку ближайшему центроиду
3. **Обновление центроидов** `new_centroid = mean(cluster_points)` вычисляет новый центр каждого кластера
4. **Проверка сходимости** `if centroids unchanged: stop` повторяет до сходимости
5. **Сложность:** O(n·k·i), где i — количество итераций

**Применимость:** сегментация, анализ данных, инициализация.

**Преимущества:** просто, быстро, масштабируемо.

**Недостатки:** требует знания k, зависит от инициализации, находит локальный оптимум.

---

## 55. Алгоритмы DBSCAN, Affinity Propagation, Spectral clustering

**DBSCAN (Density-based Spatial Clustering of Applications with Noise):**

**Определение:** алгоритм кластеризации, основанный на плотности, находит скопления точек в пространстве данных.

**Пошаговая структура:**
1. **Оператор соседства** `neighbors = find_neighbors(point, eps)` находит точки в радиусе eps
2. **Оператор классификации** `if len(neighbors) >= minPts: start_cluster()` начинает кластер
3. **Оператор расширения** рекурсивно добавляет соседних точек
4. **Классификация шума** точки без достаточных соседей становятся шумом
5. **Сложность:** O(n²) в худшем случае

**Применимость:** неправильные формы, автоматическое определение количества кластеров.

**Преимущества:** находит кластеры произвольной формы, определяет шум.

**Недостатки:** чувствителен к параметрам eps и minPts.

**Affinity Propagation:**

**Определение:** алгоритм кластеризации, основанный на обмене сообщениями между точками данных.

**Пошаговая структура:**
1. **Инициализация сходства** `S[i][j] = similarity(i, j)` вычисляет матрицу сходства
2. **Обмен сообщениями** пункты обмениваются ответственностью и доступностью
3. **Обновление матриц** обновляет R и A матрицы на основе сообщений
4. **Определение примеров** `exemplars = argmax(R + A)` выбирает примеры (центры)
5. **Сложность:** O(n²·iterations)

**Spectral Clustering:**

**Определение:** алгоритм кластеризации, использующий собственные векторы графа сходства.

**Пошаговая структура:**
1. **Построение графа сходства** создает матрицу сходства между точками
2. **Вычисление лапласиана** `L = D - W` вычисляет матрицу Лапласа
3. **Поиск собственных векторов** находит k наименьших собственных векторов матрицы L
4. **K-means кластеризация** применяет K-means к собственным векторам
5. **Сложность:** O(n³) для вычисления собственных векторов

---

## 56. Алгоритмы линейной одномерной и множественной регрессии

**Линейная регрессия:**

**Определение:** линейная одномерная регрессия — нахождение прямой линии y = a·x + b, которая лучше всего приближает данные.

**Пошаговая структура:**
1. **Вычисление средних** `mean_x = sum(x) / n; mean_y = sum(y) / n`
2. **Вычисление коэффициентов** `a = sum((x - mean_x) * (y - mean_y)) / sum((x - mean_x)²)`
3. **Вычисление пересечения** `b = mean_y - a * mean_x`
4. **Предсказание** `y_pred = a * x + b` для новых x значений
5. **Сложность:** O(n) для обучения

**Множественная регрессия** распространяет это на несколько признаков:
- **Формула:** y = a₀ + a₁·x₁ + a₂·x₂ + ... + aₖ·xₖ
- **Решение:** использует матричные операции (нормальные уравнения) O(k³)
- **Метод градиентного спуска:** O(k·iterations) итеративно

**Виды:**
- **Обыкновенная регрессия:** минимизирует сумму квадратов ошибок
- **Взвешенная регрессия:** придает разные веса разным примерам
- **Локальная регрессия:** использует взвешивание для локального приближения

**Практика применения:** прогнозирование цен, тренды данных, анализ связей.

**Преимущества:** просто, быстро, интерпретируемо.

**Недостатки:** предполагает линейную связь, чувствительна к выбросам.

---

## 57. Алгоритм логистической регрессии

**Определение:** логистическая регрессия — алгоритм классификации, предсказывающий вероятность принадлежности к классу.

**Практика применения:**
1. **Вычисление сигмоиды** `sigmoid(z) = 1 / (1 + exp(-z))` преобразует z в вероятность [0,1]
2. **Вычисление z** `z = w₀ + w₁·x₁ + w₂·x₂ + ... + wₖ·xₖ` линейная комбинация
3. **Вероятность класса** `p = sigmoid(z)` дает вероятность класса 1
4. **Классификация** `class = 1 if p > 0.5 else 0` выбирает класс по пороговому значению
5. **Обучение** градиентный спуск минимизирует кросс-энтропию функцию потерь

**Преимущества:**
- Вероятностная интерпретация
- Эффективна для бинарной классификации
- Масштабируется на большие данные

**Недостатки:**
- Линейные границы решений
- Медленнее для многоклассовой классификации
- Требует нормализации признаков

---

## 58. Нелинейная регрессия

**Определение:** нелинейная регрессия — нахождение нелинейной функции, которая приближает данные.

**Типы нелинейной регрессии:**
- **Полиномиальная:** y = a₀ + a₁·x + a₂·x² + ... + aₖ·xᵏ
- **Экспоненциальная:** y = a·e^(b·x)
- **Логарифмическая:** y = a + b·ln(x)
- **Степенная:** y = a·x^b
- **Гауссова:** y = a·exp(-(x-μ)²/(2σ²))

**Применение:**
- Полиномиальная: нелинейные тренды, приближение кривых
- Экспоненциальная: рост популяции, распад вещества
- Логарифмическая: замедляющиеся процессы
- Степенная: зависимости масштаба (закон Зипфа)

**Анализ алгоритмов:**
1. **Нелинейный метод наименьших квадратов** численно минимизирует ошибку
2. **Метод Гаусса-Ньютона** итеративно обновляет параметры
3. **Сложность:** зависит от метода оптимизации и количества параметров

---

## 59. Базовые алгоритмы нелинейной регрессии

**Градиентный спуск:**

**Определение:** метод оптимизации, движущийся в направлении отрицательного градиента для минимизации функции потерь.

**Пошаговая структура:**
1. **Инициализация весов** `w = random_weights()` или нулевые веса
2. **Вычисление градиента** `gradient = compute_gradient(w)` вычисляет производную функции потерь
3. **Обновление весов** `w = w - learning_rate * gradient` движется в сторону минимума
4. **Повторение** `while not converged:` повторяет до сходимости
5. **Сложность:** O(n·iterations) для одной итерации через все данные

**SGD (Стохастический градиентный спуск):**
1. **Случайная выборка** `for sample in shuffle(data):` берет случайный пример
2. **Обновление на примере** обновляет веса на основе одного примера
3. **Преимущество:** быстрее, может избежать локальных минимумов
4. **Сложность:** O(iterations) без зависимости от n если используется один пример

**Ансамблевые модели:**
- **Random Forest (Случайный лес):** комбинирует множество деревьев решений
- **Boosting:** последовательно строит модели, уделяя внимание ошибкам
- **Bagging:** строит модели на случайных подмножествах данных

**Деревья решений:**
1. **Выбор признака** выбирает признак, который лучше всего разделяет данные
2. **Рекурсивное разбиение** разбивает данные и рекурсивно строит поддеревья
3. **Критерий остановки** останавливается при чистоте листа или минимальном размере
4. **Сложность:** O(n·log n·k) для обучения, где k — количество признаков

**«Случайный лес» (Random Forest):**
1. **Построение деревьев** строит T деревьев на случайных подмножествах
2. **Случайный выбор признаков** на каждом узле выбирает случайное подмножество признаков
3. **Голосование** классификация — большинство голосов деревьев
4. **Регрессия** среднее значение предсказаний деревьев

**Преимущества:**
- Градиентный спуск: эффективен для большинства задач оптимизации
- SGD: быстрее на больших данных
- Ансамбли: обычно лучше чем одиночные модели
- Деревья: просто, интерпретируемо

**Недостатки:**
- Градиентный спуск: может застрять в локальном минимуме
- SGD: шумнее, требует подстройки learning rate
- Ансамбли: медленнее, требует больше памяти
- Деревья: склонны к переобучению

---

## 60. Современные и развивающиеся алгоритмы

**Алгоритмы на основе нечётких множеств:**

**Определение:** нечеткие множества позволяют элементам иметь частичную принадлежность (от 0 до 1 вместо строгих 0 или 1).

**Применение:**
- **Нечеткая логика:** размытые правила "если-то"
- **Нечеткая кластеризация:** точки могут принадлежать нескольким кластерам
- **Системы управления:** плавное управление на основе нечетких входов
- **Обработка изображений:** размытые границы объектов

**Пример:** система кредитного скоринга использует нечеткие правила (низкий/средний/высокий доход).

**Ультранечёткие множества:** расширение нечетких множеств с еще более гибким представлением членства.

**Алгоритмы на основе теории игр:**

**Применение:**
- **Равновесие Нэша:** найти стратегии, когда никто не хочет менять свой ход
- **Теория кооперативных игр:** оптимальное распределение ресурсов между игроками
- **Аукционные механизмы:** справедливое распределение товаров
- **Рекомендационные системы:** баланс между исследованием и использованием

**Алгоритмы на базе теории расписаний:**

**Применение:**
- **Планирование процессов:** оптимальное расписание задач на процессорах
- **Производственное планирование:** минимизация времени завершения всех работ
- **Распределение ресурсов:** справедливое распределение процессорного времени
- **Job Shop Scheduling:** планирование работ через машины

**Практика применения:**
- Минимизация makespan (общее время выполнения)
- Минимизация tardiness (задержки сроков)
- Балансирование нагрузки между ресурсами
- Соответствие приоритетам задач

**Преимущества современных подходов:**
- Нечеткие множества: гибкость, близко к человеческому мышлению
- Теория игр: оптимальность в многоагентных системах
- Теория расписаний: оптимальное использование ресурсов

**Недостатки:**
- Нечеткие множества: сложность определения функций членства
- Теория игр: вычислительная сложность при большом количестве игроков
- Теория расписаний: NP-полные задачи требуют эвристик

---
